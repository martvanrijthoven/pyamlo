lr: 0.001
criterion: !@torch.nn.CrossEntropyLoss
optimizer: !@torch.optim.Adam
  params: !@pyamlo.call ${model.parameters}
  lr: ${lr}

trainer_name: supervised
trainer: !include_at ./${trainer_name}.yml
  
pbar: !@ignite.handlers.ProgressBar
  persist: true

attach_pbar: !@pyamlo.call
  calling: ${pbar.attach}
  engine: ${trainer}
