{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PYAMLO Documentation","text":"<p>Development Status</p> <p>PYAMLO is currently in development. The API is not stable and may change without notice.</p> <p>PYAMLO is an advanced YAML configuration loader for Python that supports file inclusion, deep merging, environment variable injection, variable interpolation, and direct object instantiation.</p>"},{"location":"#why-pyamlo","title":"Why PYAMLO?","text":"<ul> <li>Composable configs: Use <code>include!</code> to merge multiple YAML files</li> <li>Powerful merging: Deep merge, extend lists, or patch dictionaries  </li> <li>Environment aware: Inject environment variables with defaults</li> <li>Python objects: Instantiate classes and functions directly from YAML</li> <li>Variable interpolation: Reference config values, combine strings, and access object properties with <code>${...}</code></li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install pyamlo\n</code></pre> <p>config.yaml: <pre><code>app:\n  name: MyWebApp\n  port: 8080\n  host: web.local\ngreeting: Hello, ${app.name}!\ndatabase_url: postgres://${app.host}:${app.port}/maindb\n</code></pre></p> <p>Python: <pre><code>from pyamlo import load_config\n\nconfig = load_config(\"config.yaml\")\nprint(config['greeting'])      # Hello, MyWebApp!\nprint(config['database_url'])  # postgres://web.local:8080/maindb\n</code></pre></p>"},{"location":"best-practices/","title":"Best Practices","text":""},{"location":"best-practices/#general-guidelines","title":"General Guidelines","text":"<ul> <li>Use <code>!patch</code> only when you need to completely replace a dictionary</li> <li>Use <code>!extend</code> only on lists to append items</li> <li>Always provide defaults for non-critical environment variables</li> <li>Use <code>${...}</code> for referencing both config values and object attributes</li> </ul>"},{"location":"best-practices/#environment-variables","title":"Environment Variables","text":"<p>Always provide meaningful defaults: <pre><code>db_url: !env {var: DATABASE_URL, default: \"sqlite:///default.db\"}\nlog_level: !env {var: LOG_LEVEL, default: \"INFO\"}\n</code></pre></p>"},{"location":"best-practices/#cli-overrides","title":"CLI Overrides","text":""},{"location":"best-practices/#namespace-your-arguments","title":"Namespace Your Arguments","text":"<p>Always use the <code>pyamlo.</code> prefix to avoid conflicts: <pre><code># Good\npython script.py pyamlo.app.name=MyApp --verbose\n\n# Bad - will be ignored\npython script.py app.name=MyApp --verbose\n</code></pre></p>"},{"location":"best-practices/#use-proper-yaml-syntax","title":"Use Proper YAML Syntax","text":"<p>Quote complex values and use valid YAML: <pre><code># Good\npython script.py 'pyamlo.items=!extend [4,5]' 'pyamlo.settings=!patch {\"debug\": true}'\n\n# Bad - invalid syntax\npython script.py pyamlo.items=!extend[4,5] pyamlo.settings=!patch{debug:true}\n</code></pre></p>"},{"location":"best-practices/#programmatic-vs-command-line-usage","title":"Programmatic vs Command Line Usage","text":"<p>Programmatic overrides: <pre><code>from pyamlo import load_config\n\n# Manual overrides for specific values\nconfig = load_config(\"config.yml\", overrides=[\n    \"pyamlo.app.debug=true\",\n    \"pyamlo.database.host=localhost\"\n])\n\n# Automatic CLI reading\nconfig = load_config(\"config.yml\", use_cli=True)\n\n# Combined approach\nconfig = load_config(\"config.yml\", \n    overrides=[\"pyamlo.app.name=MyApp\"],  # Always applied\n    use_cli=True  # Read additional overrides from command line\n)\n</code></pre></p> <p>Command line usage: <pre><code>python -m pyamlo config.yml pyamlo.app.debug=true pyamlo.database.host=localhost\n</code></pre></p>"},{"location":"best-practices/#processing-order","title":"Processing Order","text":"<ol> <li>File includes (<code>!include</code> directives)</li> <li>Config file values (loaded from YAML files)</li> <li>Manual overrides (via <code>overrides</code> parameter)</li> <li>CLI overrides (when <code>use_cli=True</code>)</li> </ol> <p>Manual and CLI overrides can be combined, with CLI overrides taking final precedence.</p>"},{"location":"features/","title":"Features","text":"<p>PYAMLO enhances standard YAML loading with powerful features for complex configurations.</p>"},{"location":"features/#file-inclusion","title":"File Inclusion","text":""},{"location":"features/#standard-includes-include","title":"Standard Includes (<code>include!</code>)","text":"<p>Merge multiple configuration files with deep merging: <pre><code>include!:\n  - base.yaml\n  - environment.yaml\n</code></pre></p>"},{"location":"features/#positional-includes-include_at","title":"Positional Includes (<code>!include_at</code>)","text":"<p>Include files at specific positions, replacing the key with file contents:</p> <pre><code>app:\n  name: MyApp\nmiddleware: !include_at middleware.yml\ndatabase:\n  host: localhost\n</code></pre> <p>middleware.yml: <pre><code>middleware:\n  cache:\n    enabled: true\n    ttl: 3600\n  monitoring:\n    enabled: true\n    port: 9090\n</code></pre></p> <p>Result: <pre><code>app:\n  name: MyApp\nmiddleware:\n  cache:\n    enabled: true\n    ttl: 3600\n  monitoring:\n    enabled: true\n    port: 9090\ndatabase:\n  host: localhost\n</code></pre></p>"},{"location":"features/#key-validation","title":"Key Validation","text":"<p><code>!include_at</code> validates that included files contain only expected keys:</p> <pre><code># Single key - file must contain 'config' key\nconfig: !include_at config.yml\n\n# Multiple keys - file must contain 'train_loader' and 'val_loader' keys  \ntrain_loader, val_loader: !include_at loaders.yml\n</code></pre> <p>Keys starting with underscore (e.g., <code>_helper</code>) are always allowed.</p>"},{"location":"features/#dynamic-include-paths","title":"Dynamic Include Paths","text":"<p>Use variable interpolation in file paths: <pre><code>environment: production\nconfig: !include_at configs/${environment}/api.yml\n</code></pre></p>"},{"location":"features/#multiple-config-files","title":"Multiple Config Files","text":"<p>Load and merge multiple configuration files in order: <pre><code># Base config, then environment-specific, then user overrides\nconfig = load_config(['base.yaml', 'production.yaml', 'user-override.yaml'])\n</code></pre></p>"},{"location":"features/#merging-strategies","title":"Merging Strategies","text":"<ul> <li>Deep Merge: Recursively merges dictionaries (default)</li> <li>List Extension (<code>!extend</code>): Appends to existing lists</li> <li>Dictionary Replacement (<code>!patch</code>): Completely replaces dictionaries</li> </ul>"},{"location":"features/#environment-variables-env","title":"Environment Variables (<code>!env</code>)","text":"<p>Inject environment variables with optional defaults: <pre><code>api_key: !env {var: API_KEY, default: \"not-set\"}\ndatabase_url: !env DATABASE_URL\n</code></pre></p>"},{"location":"features/#python-integration","title":"Python Integration","text":""},{"location":"features/#module-import-import","title":"Module Import (<code>!import</code>)","text":"<p>Import Python modules, classes, or functions: <pre><code>datetime: !import datetime.datetime\npathlib: !import pathlib.Path\n</code></pre></p>"},{"location":"features/#object-instantiation","title":"Object Instantiation (<code>!@</code>)","text":"<p>Create Python objects directly from YAML: <pre><code>log_path: !@pathlib.Path /var/log/app.log\ndatabase: !@psycopg2.connect\n  host: localhost\n  port: 5432\n</code></pre></p>"},{"location":"features/#variable-interpolation","title":"Variable Interpolation (<code>${...}</code>)","text":"<p>Reference other config values and perform calculations within YAML.</p>"},{"location":"features/#basic-references","title":"Basic References","text":"<pre><code>app:\n  name: MyApp\n  version: 1.0\n  title: ${app.name} v${app.version}  # \"MyApp v1.0\"\n</code></pre>"},{"location":"features/#mathematical-expressions","title":"Mathematical Expressions","text":"<pre><code>server:\n  workers: 4\n  connections_per_worker: 100\n  max_connections: ${server.workers * server.connections_per_worker}  # 400\n\npricing:\n  base_price: 10.0\n  tax_rate: 0.21\n  total: ${pricing.base_price * (1 + pricing.tax_rate)}  # 12.1\n</code></pre>"},{"location":"features/#conditional-logic","title":"Conditional Logic","text":"<pre><code>app:\n  env: production\n  debug: ${app.env == 'development'}  # false\n\ndatabase:\n  pool_size: ${50 if app.env == 'production' else 10}\n  host: ${'prod.db.com' if app.env == 'production' else 'localhost'}\n\nfeatures:\n  enable_cache: ${app.env in ['production', 'staging']}\n  rate_limiting: ${app.env == 'production' or app.env == 'staging'}\n</code></pre>"},{"location":"features/#object-property-access","title":"Object Property Access","text":"<pre><code>database: !@psycopg2.connect\n  host: localhost\n  port: 5432\n\nconnection_info: ${database.host}:${database.port}  # \"localhost:5432\"\n</code></pre>"},{"location":"features/#bitwise-operations","title":"Bitwise Operations","text":"<pre><code>permissions:\n  read: 4    # Binary: 100\n  write: 2   # Binary: 010\n  execute: 1 # Binary: 001\n\n  full_access: ${permissions.read | permissions.write | permissions.execute}  # 7\n  can_read: ${permissions.full_access &amp; permissions.read}  # 4 (truthy)\n  no_write: ${permissions.full_access &amp; ~permissions.write}  # 5\n</code></pre> <p>Supported Operations: - Math: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>//</code>, <code>%</code>, <code>**</code> - Bitwise: <code>&amp;</code>, <code>|</code>, <code>^</code>, <code>~</code>, <code>&lt;&lt;</code>, <code>&gt;&gt;</code> - Comparison: <code>==</code>, <code>!=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>in</code> - Logical: <code>and</code>, <code>or</code>, <code>not</code> - Ternary: <code>value_if_true if condition else value_if_false</code> - Ternary: <code>value_if_true if condition else value_if_false</code></p>"},{"location":"features/#cli-overrides","title":"CLI Overrides","text":"<p>Override configuration values via command line using the <code>pyamlo.</code> prefix:</p> <pre><code># Single config with overrides\npython -m pyamlo config.yml pyamlo.app.name=MyApp pyamlo.database.host=localhost\n\n# Multiple configs with overrides\npython -m pyamlo base.yml production.yml pyamlo.debug=true pyamlo.database.pool_size=20\n\n# Special tags in overrides\npython -m pyamlo config.yml 'pyamlo.items=!extend [4,5]' 'pyamlo.settings=!patch {\"debug\": true}'\n</code></pre> <p>Programmatic usage: <pre><code>from pyamlo import load_config\n\n# Manual overrides\nconfig = load_config(\"config.yml\", overrides=[\"pyamlo.app.name=MyApp\"])\n\n# Automatic CLI reading\nconfig = load_config(\"config.yml\", use_cli=True)\n\n# Combined approach\nconfig = load_config(\"config.yml\", \n    overrides=[\"pyamlo.app.name=MyApp\"],  # Manual\n    use_cli=True  # Also read from sys.argv\n)\n</code></pre></p> <p>Processing Order: 1. Include processing (per file) 2. Config file merging (left to right) 3. Manual overrides (via <code>overrides</code> parameter) 4. CLI overrides (via <code>use_cli=True</code>) 5. Variable resolution and object instantiation</p>"},{"location":"keras/","title":"Keras Integration Guide","text":"<p>PYAMLO makes Keras/TensorFlow configurations modular and reusable. This guide shows a complete MNIST CNN example.</p>"},{"location":"keras/#complete-example","title":"Complete Example","text":"<p>train.yml <pre><code># Configuration selection\ndataset_name: mnist\nmodel_name: cnn\noptimizer_name: adam\n\n# Load modular components\ndataset: !include_at datasets/${dataset_name}.yml\nmodel: !include_at models/${model_name}.yml\n\n# Training settings\nbatch_size: 32\nepochs: 1\nvalidation_split: 0.1\n\n# Compile and train\ncompile_step: !@pyamlo.call\n  calling: ${model.compile}\n  optimizer: ${optimizer_name}\n  loss: \"sparse_categorical_crossentropy\"\n  metrics: [\"accuracy\"]\n\nhistory: !@pyamlo.call\n  calling: ${model.fit}\n  x: ${dataset.x_train}\n  y: ${dataset.y_train}\n  batch_size: ${batch_size}\n  epochs: ${epochs}\n  validation_split: ${validation_split}\n  verbose: 1\n\ntest_results: !@pyamlo.call\n  calling: ${model.evaluate}\n  x: ${dataset.x_test}\n  y: ${dataset.y_test}\n  verbose: 0\n</code></pre></p>"},{"location":"keras/#components","title":"Components","text":"<p>datasets/mnist.yml <pre><code>dataset: !@keras_utils.MNISTDataset\n</code></pre></p> <p>models/cnn.yml <pre><code>model: !@tensorflow.keras.Sequential\n  layers:\n    - !@tensorflow.keras.layers.Conv2D\n        filters: 32\n        kernel_size: [3, 3]\n        activation: \"relu\"\n        input_shape: ${dataset.input_shape}\n    - !@tensorflow.keras.layers.MaxPooling2D\n        pool_size: [2, 2]\n    - !@tensorflow.keras.layers.Conv2D\n        filters: 64\n        kernel_size: [3, 3]\n        activation: \"relu\"\n    - !@tensorflow.keras.layers.MaxPooling2D\n        pool_size: [2, 2]\n    - !@tensorflow.keras.layers.Conv2D\n        filters: 64\n        kernel_size: [3, 3]\n        activation: \"relu\"\n    - !@tensorflow.keras.layers.Flatten\n    - !@tensorflow.keras.layers.Dense\n        units: 64\n        activation: \"relu\"\n    - !@tensorflow.keras.layers.Dropout\n        rate: 0.5\n    - !@tensorflow.keras.layers.Dense\n        units: ${dataset.num_classes}\n        activation: \"softmax\"\n</code></pre></p> <p>keras_utils.py <pre><code>import tensorflow as tf\n\nclass MNISTDataset:\n    def __init__(self):\n        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n        self.x_train = tf.cast(x_train, tf.float32) / 255.0\n        self.x_test = tf.cast(x_test, tf.float32) / 255.0\n\n        self.x_train = tf.expand_dims(self.x_train, axis=-1)\n        self.x_test = tf.expand_dims(self.x_test, axis=-1)\n\n        self.y_train = tf.cast(y_train, tf.int32)\n        self.y_test = tf.cast(y_test, tf.int32)\n\n        self.num_classes = 10\n        self.input_shape = (28, 28, 1)\n</code></pre></p>"},{"location":"keras/#key-features","title":"Key Features","text":"<ul> <li>Dataset Classes: Encapsulate data loading and preprocessing</li> <li>Dynamic References: Model uses <code>${dataset.input_shape}</code> and <code>${dataset.num_classes}</code></li> <li>String Optimizers: Simple <code>optimizer: \"adam\"</code> instead of complex objects</li> <li>Modular Design: Separate files for datasets and models</li> </ul>"},{"location":"keras/#running","title":"Running","text":"<pre><code>cd examples/keras\nPYTHONPATH=. python -m pyamlo train.yml\n</code></pre>"},{"location":"keras/#advanced-example","title":"Advanced Example","text":"<pre><code># With callbacks\ncallbacks:\n  - !@tensorflow.keras.callbacks.EarlyStopping\n      monitor: \"val_loss\"\n      patience: 3\n\ncompile_step: !@pyamlo.call\n  calling: ${model.compile}\n  optimizer: !@tensorflow.keras.optimizers.Adam\n    learning_rate: 0.001\n  loss: \"sparse_categorical_crossentropy\"\n  metrics: [\"accuracy\"]\n\nhistory: !@pyamlo.call\n  calling: ${model.fit}\n  x: ${dataset.x_train}\n  y: ${dataset.y_train}\n  validation_data: [${dataset.x_test}, ${dataset.y_test}]\n  epochs: 50\n  callbacks: ${callbacks}\n</code></pre>"},{"location":"pytorch-ignite/","title":"PyTorch Ignite with PYAMLO","text":"<p>This guide demonstrates using PyTorch Ignite with PYAMLO for MNIST digit classification, showcasing modular ML configuration management.</p>"},{"location":"pytorch-ignite/#quick-start","title":"Quick Start","text":""},{"location":"pytorch-ignite/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install -e .[ml]  # Install PYAMLO with ML dependencies\n</code></pre>"},{"location":"pytorch-ignite/#run-examples","title":"Run Examples","text":"<pre><code>cd examples/ignite\n\n# Monolithic approach - everything in one file\npython -m pyamlo run_monolithic.yml\n\n# Modular approach - split into focused components\npython -m pyamlo run_modular.yml\n</code></pre> <p>Both configurations will: 1. Download MNIST dataset (if not present) 2. Train a CNN model for 1 epoch 3. Evaluate on test set 4. Display training progress and final accuracy</p> <p>First Run</p> <p>The first run downloads the MNIST dataset (~9.9 MB), which may take a few moments.</p>"},{"location":"pytorch-ignite/#configuration-structure","title":"Configuration Structure","text":""},{"location":"pytorch-ignite/#file-organization","title":"File Organization","text":"<pre><code>examples/ignite/\n\u251c\u2500\u2500 run_modular.yml     # Main configuration file\n\u251c\u2500\u2500 run_monolithic.yml  # Single-file alternative\n\u251c\u2500\u2500 devices/auto.yml    # Device detection\n\u251c\u2500\u2500 datasets/\n\u2502   \u251c\u2500\u2500 selector.yml    # Dataset selection\n\u2502   \u2514\u2500\u2500 mnist.yml       # MNIST configuration\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 selector.yml    # Model selection\n\u2502   \u251c\u2500\u2500 cnn.yml         # CNN architecture\n\u2502   \u2514\u2500\u2500 resnet.yml      # ResNet architecture\n\u251c\u2500\u2500 trainers/selector.yml    # Training configuration\n\u2514\u2500\u2500 evaluators/selector.yml  # Evaluation setup\n</code></pre> <p>The modular approach provides better organization, easier maintenance, and component reusability.</p>"},{"location":"pytorch-ignite/#key-components","title":"Key Components","text":"<p>The configuration uses a selector pattern for flexible component switching:</p>"},{"location":"pytorch-ignite/#device-configuration","title":"Device Configuration","text":"<pre><code>cuda: !@torch.cuda.is_available\ndevice: !@torch.device\n  type: \"${'cuda' if cuda else 'cpu'}\"\n</code></pre>"},{"location":"pytorch-ignite/#dataset-selection","title":"Dataset Selection","text":"<pre><code>dataset_name: mnist\ntrain_dataset, val_dataset: !include_at ./${dataset_name}.yml\n\ntrain_loader: !@torch.utils.data.DataLoader\n  dataset: ${train_dataset}\n  batch_size: 64\n  shuffle: true\n</code></pre>"},{"location":"pytorch-ignite/#model-selection","title":"Model Selection","text":"<pre><code>model_name: cnn\nmodel: !include_at ./${model_name}.yml\n</code></pre>"},{"location":"pytorch-ignite/#main-configuration","title":"Main Configuration","text":"<pre><code>include!:\n  - ./devices/auto.yml \n  - ./datasets/selector.yml\n  - ./models/selector.yml\n  - ./trainers/selector.yml\n  - ./evaluators/selector.yml\n\nepochs: 1\ntrain_result: !@pyamlo.call\n  calling: ${trainer.run}\n  data: ${train_loader}\n  max_epochs: ${epochs}\n</code></pre>"},{"location":"pytorch-ignite/#usage","title":"Usage","text":""},{"location":"pytorch-ignite/#command-line-overrides","title":"Command Line Overrides","text":"<pre><code># Change learning rate\npython -m pyamlo run_modular.yml pyamlo.lr=0.01\n\n# Change model\npython -m pyamlo run_modular.yml pyamlo.model_name=resnet\n\n# Multiple overrides\npython -m pyamlo run_modular.yml pyamlo.lr=0.01 pyamlo.epochs=5 pyamlo.model_name=resnet\n</code></pre>"},{"location":"pytorch-ignite/#selector-pattern","title":"Selector Pattern","text":"<p>The modular configuration uses a selector pattern for maximum flexibility:</p> <pre><code># In any selector.yml file\ncomponent_name: default_option\ncomponent: !include_at ./${component_name}.yml\n</code></pre> <p>This pattern enables: - Runtime selection: Change components via CLI overrides - Easy extensibility: Add new components by creating new files - Clean organization: Keep related configurations together</p>"},{"location":"pytorch-ignite/#advanced-usage","title":"Advanced Usage","text":"<p>Environment variables: <pre><code>learning_rate: !env {var: LEARNING_RATE, default: 0.001}\nmodel_name: !env {var: MODEL_NAME, default: \"cnn\"}\n</code></pre></p> <p>Conditional configuration: <pre><code>is_cuda_available: !@torch.cuda.is_available\nbatch_size: \"${128 if is_cuda_available else 32}\"\n</code></pre></p>"},{"location":"pytorch-lightning/","title":"PyTorch Lightning with PYAMLO","text":"<p>This guide demonstrates using PyTorch Lightning with PYAMLO for MNIST digit classification, showcasing declarative ML configuration for Lightning workflows.</p>"},{"location":"pytorch-lightning/#quick-start","title":"Quick Start","text":""},{"location":"pytorch-lightning/#prerequisites","title":"Prerequisites","text":"<pre><code>pip install -e .[ml]  # Install PYAMLO with ML dependencies\n</code></pre>"},{"location":"pytorch-lightning/#run-example","title":"Run Example","text":"<pre><code>cd examples/lightning\n\n# Set Python path and run training\nPYTHONPATH=. python -m pyamlo train.yml\n</code></pre> <p>The training will: 1. Download MNIST dataset (if not present) 2. Train a MobileNetV2 model for 1 epoch 3. Validate after each epoch 4. Save checkpoints and logs to <code>lightning_logs/</code></p> <p>First Run</p> <p>The first run downloads the MNIST dataset (~9.9 MB), which may take a few moments.</p>"},{"location":"pytorch-lightning/#configuration-structure","title":"Configuration Structure","text":""},{"location":"pytorch-lightning/#file-organization","title":"File Organization","text":"<pre><code>examples/lightning/\n\u251c\u2500\u2500 train.yml        # Main training configuration\n\u251c\u2500\u2500 mnist.yml        # MNIST dataset configuration\n\u251c\u2500\u2500 mobilenet.yml    # MobileNetV2 model configuration\n\u251c\u2500\u2500 simple_cnn.py    # Lightning module wrapper\n\u2514\u2500\u2500 data/           # Downloaded datasets\n</code></pre>"},{"location":"pytorch-lightning/#key-components","title":"Key Components","text":""},{"location":"pytorch-lightning/#main-configuration-trainyml","title":"Main Configuration (<code>train.yml</code>)","text":"<pre><code># Dataset and model selection\ndataset: mnist\nmodel_name: mobilenet\n\n# Load configurations using !include_at\nmodel: !include_at ${model_name}.yml\ntrain_dataset, val_dataset: !include_at ${dataset}.yml\n\n# DataLoaders\ntrain_loader: !@torch.utils.data.DataLoader\n  dataset: ${train_dataset}\n  batch_size: 64\n  shuffle: true\n\nval_loader: !@torch.utils.data.DataLoader\n  dataset: ${val_dataset}\n  batch_size: 64\n  shuffle: false\n\n# Lightning model wrapper\nlightning_model: !@simple_cnn.LightningModel\n  model: ${model}\n  lr: 0.001\n\n# Lightning trainer\ntrainer: !@lightning.pytorch.Trainer\n  max_epochs: 1\n  accelerator: \"auto\"\n  devices: 1\n\n# Start training\ntrain: !@pyamlo.call\n  calling: ${trainer.fit}\n  model: ${lightning_model}\n  train_dataloaders: ${train_loader}\n  val_dataloaders: ${val_loader}\n</code></pre>"},{"location":"pytorch-lightning/#dataset-configuration-mnistyml","title":"Dataset Configuration (<code>mnist.yml</code>)","text":"<pre><code># MNIST transforms\n_mnist:\n  _transform: !@torchvision.transforms.Compose\n    transforms:\n      - !@torchvision.transforms.ToTensor\n      - !@torchvision.transforms.Normalize\n        mean: [0.1307]\n        std: [0.3081]\n\n# Datasets\ntrain_dataset: !@torchvision.datasets.MNIST\n  root: \"./data\"\n  train: true\n  download: true\n  transform: ${_mnist._transform}\n\nval_dataset: !@torchvision.datasets.MNIST\n  root: \"./data\"\n  train: false\n  download: true\n  transform: ${_mnist._transform}\n</code></pre>"},{"location":"pytorch-lightning/#model-configuration-mobilenetyml","title":"Model Configuration (<code>mobilenet.yml</code>)","text":"<pre><code>model: !@torchvision.models.mobilenet_v2\n  num_classes: 10\n</code></pre>"},{"location":"pytorch-lightning/#lightning-module-simple_cnnpy","title":"Lightning Module (<code>simple_cnn.py</code>)","text":"<p>The Lightning module wrapper adapts torchvision models for MNIST: - Modifies first layer to accept 1-channel (grayscale) input - Implements training and validation steps - Configures optimizer and logging</p>"},{"location":"pytorch-lightning/#usage","title":"Usage","text":""},{"location":"pytorch-lightning/#command-line-overrides","title":"Command Line Overrides","text":"<pre><code># Change learning rate\nPYTHONPATH=. python -m pyamlo train.yml pyamlo.lr=0.01\n\n# Change model\nPYTHONPATH=. python -m pyamlo train.yml pyamlo.model_name=mobilenet\n\n# Change dataset (if you have other datasets)\nPYTHONPATH=. python -m pyamlo train.yml pyamlo.dataset=mnist\n\n# Change training parameters\nPYTHONPATH=. python -m pyamlo train.yml pyamlo.trainer.max_epochs=5\n\n# Multiple overrides\nPYTHONPATH=. python -m pyamlo train.yml pyamlo.lr=0.01 pyamlo.trainer.max_epochs=3\n</code></pre>"},{"location":"pytorch-lightning/#expected-output","title":"Expected Output","text":"<pre><code>Epoch 1/1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 938/938 [00:45&lt;00:00, 20.67it/s, v_num=0]\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503        Test metric        \u2503       DataLoader 0        \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502         val_acc           \u2502    0.9820000529289246     \u2502\n\u2502         val_loss          \u2502    0.05834667384624481    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"pytorch-lightning/#lightning-features","title":"Lightning Features","text":""},{"location":"pytorch-lightning/#built-in-capabilities","title":"Built-in Capabilities","text":"<p>The Lightning integration automatically provides: - Distributed Training: Multi-GPU and multi-node support - Mixed Precision: Automatic 16-bit training - Checkpointing: Model state saving and resuming - Logging: TensorBoard, Weights &amp; Biases integration - Early Stopping: Automatic training termination - Progress Bars: Training progress visualization</p>"},{"location":"pytorch-lightning/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code># Enhanced trainer with more features\ntrainer: !@lightning.pytorch.Trainer\n  max_epochs: 10\n  accelerator: \"auto\"\n  devices: \"auto\"\n  precision: \"16-mixed\"  # Mixed precision training\n  enable_checkpointing: true\n  enable_progress_bar: true\n  enable_model_summary: true\n  log_every_n_steps: 50\n\n# Add callbacks\ncallbacks:\n  - !@lightning.pytorch.callbacks.ModelCheckpoint\n    monitor: \"val_acc\"\n    mode: \"max\"\n    save_top_k: 3\n  - !@lightning.pytorch.callbacks.EarlyStopping\n    monitor: \"val_loss\"\n    patience: 3\n    mode: \"min\"\n\n# Add callbacks to trainer\ntrainer: !@lightning.pytorch.Trainer\n  # ...existing config...\n  callbacks: ${callbacks}\n</code></pre>"},{"location":"pytorch-lightning/#logging-integration","title":"Logging Integration","text":"<pre><code># TensorBoard logger\ntb_logger: !@lightning.pytorch.loggers.TensorBoardLogger\n  save_dir: \"./lightning_logs\"\n  name: \"mnist_experiment\"\n\n# Weights &amp; Biases logger\nwandb_logger: !@lightning.pytorch.loggers.WandbLogger\n  project: \"mnist-classification\"\n  name: \"mobilenet-experiment\"\n\n# Add logger to trainer\ntrainer: !@lightning.pytorch.Trainer\n  # ...existing config...\n  logger: ${tb_logger}  # or ${wandb_logger}\n</code></pre>"},{"location":"pytorch-lightning/#customization-examples","title":"Customization Examples","text":""},{"location":"pytorch-lightning/#different-model-architectures","title":"Different Model Architectures","text":"<p>Create new model configuration files:</p> <p><code>resnet.yml</code>: <pre><code>model: !@torchvision.models.resnet18\n  num_classes: 10\n</code></pre></p> <p><code>efficientnet.yml</code>: <pre><code>model: !@torchvision.models.efficientnet_b0\n  num_classes: 10\n</code></pre></p> <p>Then switch models: <pre><code>PYTHONPATH=. python -m pyamlo train.yml pyamlo.model_name=resnet\n</code></pre></p>"},{"location":"pytorch-lightning/#environment-variables","title":"Environment Variables","text":"<pre><code># Use environment variables for configuration\nlearning_rate: !env {var: LEARNING_RATE, default: 0.001}\nbatch_size: !env {var: BATCH_SIZE, default: 64}\nmax_epochs: !env {var: MAX_EPOCHS, default: 1}\n</code></pre>"},{"location":"pytorch-lightning/#conditional-configuration","title":"Conditional Configuration","text":"<pre><code># Adapt configuration based on hardware\nis_cuda_available: !@torch.cuda.is_available\nbatch_size: \"${128 if is_cuda_available else 32}\"\ndevices: \"${'auto' if is_cuda_available else 1}\"\n</code></pre>"},{"location":"pytorch-lightning/#lightning-vs-ignite","title":"Lightning vs Ignite","text":"Feature PyTorch Lightning PyTorch Ignite Learning Curve Steeper (more opinionated) Gentler (more flexible) Boilerplate Minimal More manual setup Built-in Features Extensive Manual implementation Customization Through Lightning modules Direct event handling Best For Standard workflows Custom training loops <p>Both integrate seamlessly with PYAMLO's configuration management, allowing you to choose the right tool for your specific needs.</p>"},{"location":"pytorch-lightning/#best-practices","title":"Best Practices","text":"<ol> <li>Modular Configuration: Split datasets, models, and training configs into separate files</li> <li>Environment Variables: Use <code>!env</code> for deployment-specific settings</li> <li>CLI Overrides: Leverage command line overrides for experimentation</li> <li>Validation: Use <code>!include_at</code> validation to ensure configuration consistency</li> <li>Logging: Configure appropriate loggers for experiment tracking</li> <li>Callbacks: Use Lightning callbacks for checkpointing and early stopping</li> </ol> <p>The Lightning integration demonstrates PYAMLO's ability to manage complex ML frameworks through declarative configuration, making experimentation and deployment more systematic and reproducible.</p>"}]}